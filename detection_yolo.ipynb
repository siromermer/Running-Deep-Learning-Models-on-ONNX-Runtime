{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20a8ecf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.8.0+cu128\n",
      "CUDA available: True\n",
      "CUDA version: 12.8\n",
      "cuDNN version: 91002\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "\n",
    "print(\"cuDNN version:\", torch.backends.cudnn.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b62daa69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.22.0\n",
      "GPU\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime\n",
    "\n",
    "print(onnxruntime.__version__)\n",
    "print(onnxruntime.get_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0755dc",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217d98cf",
   "metadata": {},
   "source": [
    "# Object Detection with YOLOv8 and ONNX Runtime GPU\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Export a pre-trained YOLOv8 model to ONNX format\n",
    "2. Run the model on video using ONNX Runtime with GPU acceleration\n",
    "3. Visualize object detection results in real-time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c612ee42",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4a3544",
   "metadata": {},
   "source": [
    "## 1. Export YOLOv8 model to ONNX format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1aee6152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.183 ðŸš€ Python-3.10.18 torch-2.8.0+cu128 CPU (AMD Ryzen 7 4800H with Radeon Graphics)\n",
      "YOLOv8n summary (fused): 72 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'models/yolov8n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (6.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.64...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 1.1s, saved as 'models/yolov8n.onnx' (12.2 MB)\n",
      "\n",
      "Export complete (1.3s)\n",
      "Results saved to \u001b[1m/home/omer/dl-files/Running-Deep-Learning-Models-on-ONNX-Runtime/models\u001b[0m\n",
      "Predict:         yolo predict task=detect model=models/yolov8n.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=models/yolov8n.onnx imgsz=640 data=coco.yaml  \n",
      "Visualize:       https://netron.app\n",
      "YOLOv8 model exported to models/yolov8n.onnx with input size 640x640\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Define model input dimensions\n",
    "model_width = 640\n",
    "model_height = 640\n",
    "\n",
    "# Load pretrained YOLOv8 model\n",
    "model = YOLO('models/yolov8n.pt')\n",
    "\n",
    "# Export the model to ONNX format\n",
    "model.export(format='onnx')\n",
    "\n",
    "print(f\"YOLOv8 model exported to models/yolov8n.onnx with input size {model_width}x{model_height}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14245408",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8aab9e1",
   "metadata": {},
   "source": [
    "## 2. Run YOLOv8 model on video with ONNX Runtime GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db530acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available ONNX Runtime providers: ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\n",
      "CUDA provider available: True\n",
      "Session providers: ['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
      "Input name: images\n",
      "Loaded 91 class names\n",
      "Using model input dimensions: 640x640\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Check available providers first\n",
    "print(\"Available ONNX Runtime providers:\", ort.get_available_providers())\n",
    "print(\"CUDA provider available:\", 'CUDAExecutionProvider' in ort.get_available_providers())\n",
    "\n",
    "# Load ONNX model\n",
    "session = ort.InferenceSession(\"models/yolov8n.onnx\", providers=['CUDAExecutionProvider'])\n",
    "print(\"Session providers:\", session.get_providers())\n",
    "\n",
    "# Get input details\n",
    "input_name = session.get_inputs()[0].name\n",
    "print(f\"Input name: {input_name}\")\n",
    "\n",
    "# Load COCO class names from file\n",
    "with open('resources/coco_labels_yolo.txt', 'r') as f:\n",
    "    class_names = [line.strip() for line in f.readlines()]\n",
    "print(f\"Loaded {len(class_names)} class names\")\n",
    "print(f\"Using model input dimensions: {model_width}x{model_height}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2974b4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_yolo_output(outputs, original_shape, conf_threshold=0.3, iou_threshold=0.45):\n",
    "    \"\"\"Post-process YOLOv8 ONNX output\"\"\"\n",
    "    predictions = outputs[0]  # Shape: [1, 84, 8400]\n",
    "    predictions = predictions[0]  # Remove batch dimension: [84, 8400]\n",
    "    predictions = predictions.T  # Transpose to [8400, 84]\n",
    "    \n",
    "    # Extract boxes and scores\n",
    "    boxes = predictions[:, :4]  # First 4 columns are bbox coordinates\n",
    "    scores = predictions[:, 4:]  # Remaining columns are class scores\n",
    "    \n",
    "    # Get the class with highest score for each detection\n",
    "    class_ids = np.argmax(scores, axis=1)\n",
    "    confidences = np.max(scores, axis=1)\n",
    "    \n",
    "    # Filter by confidence threshold\n",
    "    valid_detections = confidences > conf_threshold\n",
    "    boxes = boxes[valid_detections]\n",
    "    confidences = confidences[valid_detections]\n",
    "    class_ids = class_ids[valid_detections]\n",
    "    \n",
    "    # Convert from center format to corner format\n",
    "    x_center, y_center, width, height = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3]\n",
    "    x1 = x_center - width / 2\n",
    "    y1 = y_center - height / 2\n",
    "    x2 = x_center + width / 2\n",
    "    y2 = y_center + height / 2\n",
    "    \n",
    "    boxes = np.column_stack((x1, y1, x2, y2))\n",
    "    \n",
    "    # Scale boxes to original image size\n",
    "    orig_h, orig_w = original_shape[:2]\n",
    "    boxes[:, [0, 2]] *= orig_w / model_width  # Scale x coordinates\n",
    "    boxes[:, [1, 3]] *= orig_h / model_height  # Scale y coordinates\n",
    "\n",
    "    # Apply Non-Maximum Suppression to eliminate duplicate detections\n",
    "    indices = cv2.dnn.NMSBoxes(boxes.tolist(), confidences.tolist(), conf_threshold, iou_threshold)\n",
    "\n",
    "    # Check if any boxes remain after NMS\n",
    "    if len(indices) > 0:\n",
    "        indices = indices.flatten()\n",
    "        return boxes[indices], confidences[indices], class_ids[indices]\n",
    "    else:\n",
    "        return [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7eb6fec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running YOLOv8 with ONNX Runtime on GPU...\n",
      "Press 'q' to quit the video display\n",
      "Video processing completed!\n"
     ]
    }
   ],
   "source": [
    "# Process video with YOLOv8\n",
    "# You can change the video path and confidence threshold here\n",
    "video_path = \"resources/test_video_street.mp4\"\n",
    "confidence_threshold = 0.3\n",
    "iou_threshold = 0.45\n",
    "\n",
    "# Open video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# FPS calculation variables\n",
    "fps_counter = 0\n",
    "fps_start_time = time.time()\n",
    "fps_display = 0.0\n",
    "\n",
    "# Determine device string for display\n",
    "device_str = \"GPU\" if 'CUDAExecutionProvider' in session.get_providers() else \"CPU\"\n",
    "print(f\"\\nRunning YOLOv8 with ONNX Runtime on {device_str}...\")\n",
    "print(\"Press 'q' to quit the video display\")\n",
    "\n",
    "# Loop through video frames\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # YOLOv8 preprocessing\n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    img_resized = cv2.resize(img, (model_width, model_height))\n",
    "    img_resized = img_resized.astype(np.float32) / 255.0\n",
    "    img_resized = np.transpose(img_resized, (2, 0, 1))  # HWC -> CHW\n",
    "    img_resized = np.expand_dims(img_resized, axis=0)\n",
    "\n",
    "    # Run inference\n",
    "    outputs = session.run(None, {input_name: img_resized})\n",
    "\n",
    "    # Post-process outputs\n",
    "    boxes, confidences, class_ids = postprocess_yolo_output(outputs, frame.shape, \n",
    "                                                          conf_threshold=confidence_threshold,\n",
    "                                                          iou_threshold=iou_threshold)\n",
    "\n",
    "    # Draw detections\n",
    "    for box, conf, cls_id in zip(boxes, confidences, class_ids):\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        \n",
    "        # Ensure coordinates are within frame bounds\n",
    "        x1, y1 = max(0, x1), max(0, y1)\n",
    "        x2, y2 = min(width, x2), min(height, y2)\n",
    "        \n",
    "        # Draw bounding box\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        \n",
    "        # Draw label\n",
    "        label = f\"{class_names[cls_id]}: {conf:.2f}\"\n",
    "        label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)[0]\n",
    "        cv2.rectangle(frame, (x1, y1 - label_size[1] - 10), \n",
    "                     (x1 + label_size[0], y1), (0, 255, 0), -1)\n",
    "        cv2.putText(frame, label, (x1, y1 - 5),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
    "\n",
    "    # Add title at top middle of screen\n",
    "    title_text = \"YOLOv8 Object Detection\"\n",
    "    title_size = cv2.getTextSize(title_text, cv2.FONT_HERSHEY_SIMPLEX, 1.0, 2)[0]\n",
    "    title_x = (width - title_size[0]) // 2\n",
    "    cv2.rectangle(frame, (title_x - 10, 10), (title_x + title_size[0] + 10, 50), (0, 0, 0), -1)\n",
    "    cv2.putText(frame, title_text, (title_x, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)\n",
    "\n",
    "    # Calculate and display FPS\n",
    "    fps_counter += 1\n",
    "    if fps_counter % 10 == 0:\n",
    "        fps_end_time = time.time()\n",
    "        fps_display = 10 / (fps_end_time - fps_start_time)\n",
    "        fps_start_time = fps_end_time\n",
    "    \n",
    "    # Draw FPS\n",
    "    fps_text = f\"FPS: {fps_display:.1f} (YOLOv8-{device_str})\"\n",
    "    cv2.rectangle(frame, (5, height - 40), (280, height - 10), (0, 0, 0), -1)\n",
    "    cv2.putText(frame, fps_text, (10, height - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "    # Display \n",
    "    cv2.imshow(\"YOLOv8 ONNX Runtime\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release everything\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"Video processing completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157668cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onnxruntime-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
